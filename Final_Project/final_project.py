# -*- coding: utf-8 -*-
"""final project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WIV57WjICiNE4pblPip5zIrha63xAjZT
"""

ll

from google.colab import drive
import os
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/Shareddrives/影像處理期末專題

#%tensorflow_version 1.x
import os
import tensorflow as tf
TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']
tf.logging.set_verbosity(tf.logging.INFO)

!nvidia-smi

# !unzip food_11.zip

# coding=utf-8
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import tensorflow as tf
import time
from keras.callbacks import TensorBoard

# 資料路徑
DATASET_PATH = 'training'  
train_data_dir = 'training'
valid_data_dir = 'validation'

# 影像大小
IMAGE_SIZE = (512, 512)

# 影像類別數
NUM_CLASSES = 11

# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路
BATCH_SIZE = 16

# 凍結網路層數
FREEZE_LAYERS = 2

# Epoch 數
NUM_EPOCHS = 20

# 模型輸出儲存的檔案
WEIGHTS_FINAL = 'food-11-1230-tpu.h5'

# 透過 data augmentation 產生訓練與驗證用的影像資料
'''train_datagen = ImageDataGenerator(rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   channel_shift_range=10,
                                   horizontal_flip=True,
                                   fill_mode='nearest')
train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',
                                                  target_size=IMAGE_SIZE,
                                                  interpolation='bicubic',
                                                  class_mode='categorical',
                                                  shuffle=True,
                                                  batch_size=BATCH_SIZE)

valid_datagen = ImageDataGenerator()
valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',
                                                  target_size=IMAGE_SIZE,
                                                  interpolation='bicubic',
                                                  class_mode='categorical',
                                                  shuffle=False,
                                                  batch_size=BATCH_SIZE)'''
#train_datagen = ImageDataGenerator()
train_datagen = ImageDataGenerator(rotation_range=40,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    shear_range=0.2,
                    zoom_range=0.2,
                    channel_shift_range=10,
                    horizontal_flip=True,
                    fill_mode='nearest')
train_batches = train_datagen.flow_from_directory(train_data_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical') # set as training data
valid_datagen = ImageDataGenerator()
valid_batches = valid_datagen.flow_from_directory(valid_data_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical') # set as validation data

# 輸出各類別的索引值
for cls, idx in train_batches.class_indices.items():
    print('Class #{} = {}'.format(idx, cls))

print("train data samples : " + str(train_batches.samples) + "\nvalidation data samples : " + str(valid_batches.samples))

# 以訓練好的 ResNet50 為基礎來建立模型，
# 捨棄 ResNet50 頂層的 fully connected layers
net = ResNet50(include_top=False, weights="imagenet", input_tensor=None,
               input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
x = net.output
x = Flatten()(x)

# 增加 DropOut layer
x = Dropout(0.5)(x)

# 增加 Dense layer，以 softmax 產生個類別的機率值
output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)

# 設定凍結與要進行訓練的網路層
net_final = Model(inputs=net.input, outputs=output_layer)
for layer in net_final.layers[:FREEZE_LAYERS]:
    layer.trainable = False
for layer in net_final.layers[FREEZE_LAYERS:]:
    layer.trainable = True

'''tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
strategy = tf.distribute.experimental.TPUStrategy(tpu)'''
'''resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_host(resolver.master())
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)'''

# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning
net_final.compile(optimizer=Adam(lr=1e-5),
                  loss='categorical_crossentropy', metrics=['accuracy'])

# 輸出整個網路結構
print(net_final.summary())

# tensorboard
NAME="Food-11-{}".format(int(time.time()))
tensorboard=TensorBoard(log_dir='log/{}'.format(NAME))

# 訓練模型
net_final.fit_generator(train_batches,
            steps_per_epoch=train_batches.samples // BATCH_SIZE,
            validation_data=valid_batches,
            validation_steps=valid_batches.samples // BATCH_SIZE,
            epochs=NUM_EPOCHS,
            callbacks = [tensorboard])

'''tpu_model.fit_generator(train_batches,
            steps_per_epoch=train_batches.samples // BATCH_SIZE,
            validation_data=valid_batches,
            validation_steps=valid_batches.samples // BATCH_SIZE,
            epochs=NUM_EPOCHS,
            callbacks = [tensorboard])'''

# 儲存訓練好的模型
net_final.save(WEIGHTS_FINAL)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir log